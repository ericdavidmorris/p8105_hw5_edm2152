---
title: "p8105_hw5_edm2152"
author: "Eric Morris"
date: "11/6/2018"
output: github_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(tidyverse)
library(p8105.datasets)
library(rvest)
library(purrr)

knitr::opts_chunk$set(
  fig.align = "center",
  dpi = 300
)
```

## Problem 1 

```{r, Importing and Tidying Data, message = FALSE}

one_df = 
  tibble(participant = list.files("./data", full.names = TRUE)) %>% # Getting all file names using list.files
  mutate(long_data = map(participant, read_csv)) %>% # Using map, similar to Napoleon Dynamite Example to read in the data for each subject
  unnest()

one_df_tidy = # Creating a new data frame for the tidy version of this dataset and tidying 
  one_df %>% 
  separate(participant, into = c("arm", "id"), sep = "_") %>% 
  separate(arm, into = c("filler1", "arm"), sep = "a/") %>% 
  separate(id, into = c("id", "filler2"), sep = ".c") %>% 
  select(-starts_with("fill")) %>% 
  mutate(arm = str_replace(arm, "con", "control"),
         arm = str_replace(arm, "exp", "experimental")) %>%
  gather(key = week, value = observation, week_1:week_8) %>% 
  separate(week, into = c("filler", "week"), sep = "_") %>% 
  select(-filler) %>% 
  mutate(week = as.numeric(week))
```


```{r, Spaghetti Plot}

# I initially converted the id variable to a numeric variable in my tidying above. However, that wasn't working in my plot, so needed to remove that 
# and leave id as a character so I could specificy type in my ggplot to get a line for each participant 

one_df_tidy %>% 
  group_by(arm, id) %>% 
  ggplot(aes(x = week, y = observation, color = arm, type = id)) + 
  geom_point() +
  geom_line() + 
  theme_bw() +
  scale_x_continuous(breaks = seq(1, 8, 1)) + 
  scale_y_continuous(breaks = seq(-2.5, 8, 0.5)) + 
  labs(title = "Subject Observations Over Time by Treatment Arm", 
       x = "Week Number",
       y = "Observation Value") 
 
# + facet_grid(~arm) decided not to include this and overlay the two arms in one plot 

```

From our line plot, we can see that there appears to be a clear difference between the control and experimental arms. The experimental group appears to increase over time in observation value and the control group appears to hover around the same value or slightly decrease over time. 

## Problem 2 

```{r, Importing Homicide Data, message = FALSE}

# I imported the raw file straight from GitHub, just in case the data is updated in the future then those updates will be incoporated in my code

wp_homicide_data_raw = 
  read_csv("https://raw.githubusercontent.com/washingtonpost/data-homicides/master/homicide-data.csv") %>% 
  janitor::clean_names()

num_cities = 
  wp_homicide_data_raw %>% 
  group_by(city) %>% 
  distinct(city) %>% 
  nrow()

```

The Washington Post homicide dataset contains data on `r nrow(wp_homicide_data_raw )` homicides across `r num_cities` major U.S. cities ranging from 2007 to 2015. There are `r ncol(wp_homicide_data_raw )` total variables which include the victim's full name, race, age, and whether or not the homicide case was solved (termed "disposition"). Additionally the dataset provides an ID number, report date, and specific location of the homicide via latitude and longitude coordinates. 

```{r, Manipulating the Data}

# Adding the city state variable by concatenating the two existing location variables 

wp_homicide_data = 
  wp_homicide_data_raw %>% 
  mutate(city_state = str_c(city, state, sep = ", ")) 

# Filtering out unsolved homicides 

unsolved_homicides = 
  wp_homicide_data %>% 
  group_by(city_state) %>% 
  filter(disposition %in% c("Closed without arrest", "Open/No arrest")) %>%
  summarize(unsolved = n())

# Total homicides in the data set

total_homicides = 
  wp_homicide_data %>% 
  group_by(city_state) %>% 
  summarize(total = n())

# Joining the two, creating a data set with city_state variable, unsolved homicides and total homicides 

homicide_vals = 
  left_join(unsolved_homicides, total_homicides, by = "city_state") %>% 
  arrange(-total)

```


```{r, Baltimore}

# Creating a function for prop.test for repeated use, also adding in the eventual broom::tidy in the function

est_prop_unsolved = function(df) {
  
  unsolved_data = prop.test(df$unsolved, df$total)
  
  broom::tidy(unsolved_data) %>% 
    select(estimate, conf.low, conf.high)
}

baltimore_est_prop = 
  homicide_vals %>% 
  filter(city_state == "Baltimore, MD") %>% 
  est_prop_unsolved()

baltimore_est_prop %>% 
  knitr::kable()

```

Here we see an estimated proportion of 0.6456, with a lower bound of 0.6276 and an upper bound of 0.6632 in a 95% CI. 

```{r, all cities data for plot}
# this is similar to the map from #1, I nested all the cities and ran a map for my est function from above for all the cities

all_cities_nest = nest(homicide_vals, unsolved, total)

all_unsolved = 
  all_cities_nest %>% 
  mutate(all_prop_unsolved = map(data, est_prop_unsolved)) %>% 
  unnest()
```

```{r, plotting estimates}
# Using factor reorder to list cities in descending order of their estimate and using geom_errorbar


all_unsolved %>% 
  mutate(city_state = fct_reorder(city_state, estimate)) %>% 
  ggplot(aes(x = city_state, y = estimate)) + 
  geom_point(color = "firebrick") + 
  geom_errorbar(aes(ymin = conf.low, ymax = conf.high)) + 
  coord_flip() +
  labs(title = "Proportion of Unsolved Homicides in 50 Major US Cities", 
       y = "Proportion of Unsolved Homicide Cases", 
       x = "City, State", 
       caption = "Error Bars represent 95% Confidence Interval of Estimated Proportion") + 
  theme(axis.text.x = element_text(size = 3)) + 
  theme_bw()
```

In the above plot, we see that among the 50 major cities for which we have data, Chicago has the highest proportion of unsolved homicide cases in this dataset and Richmond, VA has the lowest estimate. In the future, I think this data would be more interesting had it been weighted or incorporated a per capita measure. 
